{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahulchauhan1612/Bike-Sharing-Demand-Prediction/blob/main/Copy_of_Bike_Sharing_Demand_Prediction_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOGC-qoyhJeX"
      },
      "source": [
        "# <b><u> Project Title : Seoul Bike Sharing Demand Prediction </u></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Abstract:\n",
        "\n",
        "Bike sharing as we know is a transport service primary focus to lend conventional or electrical bikes to an individual or a group of individuals in order to let them travel in city or outskirt in rent for an hour, a day or for a month depending on the needs.\n",
        "\n",
        "In market share we can see that Bike Sharing system has a global market share which was valued around 3.39 billion Dollars in 2019 and is projected to grow to 6.98 Billion Dollars by 2027 with a compound annual growth rate of around 14% indicatively from 2020 to 2027.\n",
        "\n",
        "Several factors such as low bike rent, increase in capital investments,introduction of e-bikes in the market, technological advancement and government schemes for development of several bike-sharing infrastructure has increased the overall market share and led to the introduction of several opportunities during the forecasted year. However, rise in bike theft and huge initial investment are some of the key factors in order to hinder expected market growth.\n",
        "\n",
        "*# Keywords: Bike-Sharing, Data Mining, Predictive Analysis, Linear Regression, Machine Learning.*"
      ],
      "metadata": {
        "id": "0SGzygQSnzAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction:**\n",
        "\n",
        "Bike sharing system demand nowadays is increasing in proportional manners globally. This system has gained a lot of attention with its cost effective system and easy to use nature. This system has already attracted a huge customer base globally like in South Korea, São Paulo ,China and Australia. Bike sharing system generally rents bikes on an hour, day and month basis and is generally based on static pricing inclusive of hour,days or month. Because of its affordability and easy renting system anyone can commute on arrival. According to our problem our main aim is to build a predictive model so as to find the number of bikes rented based on the given dataset."
      ],
      "metadata": {
        "id": "2FyEd_80ov_p"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06xIdG26kRF"
      },
      "source": [
        "## <b> Problem Description </b>\n",
        "\n",
        "### Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlLxAtlziMbP"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "### <b> The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information.</b>\n",
        "\n",
        "\n",
        "### <b>Attribute Information: </b>\n",
        "\n",
        "* ### Date : year-month-day\n",
        "* ### Rented Bike count - Count of bikes rented at each hour\n",
        "* ### Hour - Hour of he day\n",
        "* ### Temperature-Temperature in Celsius\n",
        "* ### Humidity - %\n",
        "* ### Windspeed - m/s\n",
        "* ### Visibility - 10m\n",
        "* ### Dew point temperature - Celsius\n",
        "* ### Solar radiation - MJ/m2\n",
        "* ### Rainfall - mm\n",
        "* ### Snowfall - cm\n",
        "* ### Seasons - Winter, Spring, Summer, Autumn\n",
        "* ### Holiday - Holiday/No holiday\n",
        "* ### Functional Day - NoFunc(Non Functional Hours), Fun(Functional hours)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dByMsuzT8Tnw"
      },
      "source": [
        "# Importing required modules and loading dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime as dt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set_style(\"whitegrid\",{'grid.linestyle': '--'})\n",
        "\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KoxBRIGApIe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Supervised ML - Regression/SeoulBikeData.csv\",encoding= 'unicode_escape')\n",
        "\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "CqeZwnnXpUgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting shape of the data\n",
        "df.shape"
      ],
      "metadata": {
        "id": "ATj1TecHpYI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting details about all the features present in the dataset\n",
        "df.info()"
      ],
      "metadata": {
        "id": "9Y5ZfYelqnh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see there are ***6 float, 4 int , 4 object or str type data*** available in the dataset. \n",
        "\n",
        "Also there is ***8760 rows*** and ***14 columns*** or feature. Also there is **8760 not null values**. \n",
        "\n",
        "We can conclude all of the above after final feature engineering:(i.e feature creation,feature selection etc)"
      ],
      "metadata": {
        "id": "57tJOKk-q4uy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **# Feature Description :-**\n",
        "\n",
        "1. Date : Date feature which is str type is needed to convert it into Datetime format DD/MM/YYYY.\n",
        "2.Hour: Hour feature which is in 24 hour format which tells us number bike rented per hour is int type.\n",
        "3.Temperature(°C): Temperature feature which is in celsius scale(°C) is Float type.\n",
        "4.Humidity(%): Feature humidity in air (%) which is int type.\n",
        "5.Wind speed (m/s) : Wind Speed feature which is in (m/s) is float type.\n",
        "6.Visibility (10m): Visibility feature which is in 10m, is int type.\n",
        "7.Dew point temperature(°C): Dew point Temperature in (°C) which tells us temperature at the start of the day is Float type.\n",
        "8.Solar Radiation (MJ/m2): Solar radiation or UV radiation is Float type.\n",
        "9.Rainfall(mm): Rainfall feature in mm which indicates 1 mm of rainfall which is equal to 1 litre of water per metre square is Float type.\n",
        "10.Snowfall (cm): Snowfall in cm is Float type. Seasons: Season, in this feature four seasons are present in data is str type.\n",
        "11.Holiday: whether no holiday or holiday can be retrieved from this feature is str type.\n",
        "12.Functioning Day: Whether the day is Functioning Day or not can be retrieved from this feature is str type."
      ],
      "metadata": {
        "id": "8Xj_PU-msuFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **#Processing the dataset :-**\n",
        "\n"
      ],
      "metadata": {
        "id": "YCM7jebAtBP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for duplicated values\n",
        "len(df[df.duplicated()])"
      ],
      "metadata": {
        "id": "GOHhF0QMtDt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for total null values\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "d8AQAl6stnFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **No duplicate records are found in the dataset.Now we can proceed further**"
      ],
      "metadata": {
        "id": "ocJFDVugtzmR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Breaking down Date column into 3 columns, namely Day, Month, Year.**"
      ],
      "metadata": {
        "id": "m7yzCDjKt5No"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using Lambda function to strip date from string to Datetime format so to retrieve d,m,y\n",
        "df['Date'] = df['Date'].apply(lambda x:dt.strptime(x, \"%d/%m/%Y\"))\n",
        "df['Day'] = df['Date'].dt.day_name()\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['Year'] = df['Date'].dt.year"
      ],
      "metadata": {
        "id": "omIjMMjJu2ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "FCwJiUfRvDNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets add a new column named Weekend with binary values, indicating 1 for weekend and 0 for a weekday\n",
        "\n",
        "df['Weekend']=df['Day'].apply(lambda x : 1 if x=='Saturday' or x=='Sunday' else 0 )"
      ],
      "metadata": {
        "id": "cAA30EkxvEQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "_qEtpRS0vVbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping columns in vertical axis\n",
        "df=df.drop(columns=['Date','Day','Year'],axis=1)"
      ],
      "metadata": {
        "id": "7jr8SgQkvoqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#counting Functioning Day using value value_count\n",
        "df['Functioning Day'].value_counts()"
      ],
      "metadata": {
        "id": "B8bbLZuHvrqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **#Exploratory Data Analysis :-**"
      ],
      "metadata": {
        "id": "WDuMCBCXvwN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation of number of rented bikes vs Months:\n",
        "\n",
        "fig,ax=plt.subplots(figsize=(18,8))\n",
        "sns.barplot(data=df,x='Month',y='Rented Bike Count',color = 'brown' , ci=None)\n",
        "ax.set_title('Average Rented bikes per day Vs Month ' , fontsize=18)\n",
        "ax.set_xlabel('Months',fontsize=15)\n",
        "ax.set_ylabel('Average Rented bikes per day',fontsize=15)"
      ],
      "metadata": {
        "id": "UJ7jz-l4v2OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation of average number of rented bikes vs Weekday or Weekend:\n",
        "\n",
        "fig,ax=plt.subplots(figsize=(5,8))\n",
        "sns.barplot(data=df,x='Weekend',y='Rented Bike Count',ax=ax,ci=None , color ='brown')\n",
        "ax.set_title('Rented bikes Vs Weekend ' , fontsize=18)\n",
        "ax.set_xlabel('Weekend',fontsize=15)\n",
        "ax.set_ylabel('Average Rented Bikes per day',fontsize=15)"
      ],
      "metadata": {
        "id": "CjnRSCr1xT0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation of Rented bikes vs Hour of the Day:\n",
        "\n",
        "fig,ax=plt.subplots(figsize=(20,10))\n",
        "sns.barplot(data=df,x='Hour',y='Rented Bike Count',ci= None ,  color ='brown')\n",
        "ax.set_title('Avergae Rented Bikes per day Vs Hour ', fontsize=18)\n",
        "ax.set_xlabel('Hour',fontsize=15)\n",
        "ax.set_ylabel('Rented Bikes',fontsize=15)"
      ],
      "metadata": {
        "id": "R68e3cdCxYQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation of Average Rented bikes vs Hour of the Day by Weekend or Weeknday:\n",
        "\n",
        "fig,ax=plt.subplots(figsize=(15,8))\n",
        "sns.pointplot(data=df,x='Hour',y='Rented Bike Count',hue='Weekend',ci= None, color ='green' )\n",
        "ax.set_title('Average Rented bikes per day Vs Hours according to Weekend or Weekday ' , fontsize=18)\n",
        "ax.set_xlabel('Hour',fontsize=20)\n",
        "ax.set_ylabel('Rented Bikes',fontsize=15)"
      ],
      "metadata": {
        "id": "JhG6T9J8wOeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this visualizalisation we can conclude the following:\n",
        "\n",
        "1. In ***Average Bike Rented vs Hour*** we can clearly see that at ***6:00 PM*** average number of bike rented by the people was ***1550***. While at ***00.00 or at midnight*** average bike rented was lowest with just around ***550 bikes*** which were ***on weekdays***.\n",
        "\n",
        "2. In ***Average Bike Rented vs Hou***r we can also see that at 5:00 PM average number of bike rented by the people was around ***1150***. While at **00.00 or at midnight** average bike rented was lowest with just around ***650 bikes*** which were ***on weekend***."
      ],
      "metadata": {
        "id": "8cKf7_ruxoY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation of Average Bike rented vs Month:\n",
        "\n",
        "avg_bike=df.groupby('Month')['Rented Bike Count'].mean()\n",
        "plt.figure(figsize=(12,4))\n",
        "s=avg_bike.plot(legend=True, marker='o',title=f'Average Bike rented vs Month',color='green')\n",
        "s.set_xticks(range(len(avg_bike)))\n",
        "s.set_xticklabels(avg_bike.index.tolist(),rotation = 85)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "owP2McO4xo2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  In ***Average Bike Rented vs Month*** we can clearly see that Average Bike rented in*** July*** was highest around ***1250*** and Average Bike Rented during month of ***February*** was the Lowest with just **200** average bike.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fLwUkbZo24Ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis of rented Bikes Vs Functioning Day:\n",
        "\n",
        "fig,ax=plt.subplots(figsize=(6,8))\n",
        "sns.barplot(data=df,x='Functioning Day',y='Rented Bike Count', ci=None,color = 'brown' )\n",
        "ax.set_title('Rented bikes Vs Functioning Day ', fontsize=18)\n",
        "ax.set_xlabel('Functioning Day',fontsize=15)\n",
        "ax.set_ylabel('Average Rented Bikes',fontsize=15)"
      ],
      "metadata": {
        "id": "_m7XTK9U2613"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   From this Bar Plot we can conclude that Bikes are rented only on **functioning day.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M18PDbvV3LAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis of Rented Bikes Vs Seasons:\n",
        "\n",
        "fig,ax=plt.subplots(figsize=(10,7))\n",
        "sns.barplot(data=df,x='Seasons',y='Rented Bike Count', color ='brown', ci= None , estimator= sum)\n",
        "ax.set_title('Rented bikes Vs Seasons ' , fontsize=18)\n",
        "ax.set_xlabel('Seasons',fontsize=15)\n",
        "ax.set_ylabel('Rented Bikes',fontsize=15)"
      ],
      "metadata": {
        "id": "9P6rrDN63NcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   From this Bar Plot we can see that ***Highest number of bikes*** were rented during ***Summer seasons*** while **least number of bikes** were rented during ***Winter seasons***.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1bCIUvro3ZJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis of Rented Bikes Vs Holiday or not:\n",
        "\n",
        "fig,ax=plt.subplots(figsize=(10,7))\n",
        "sns.barplot(data=df,x='Holiday',y='Rented Bike Count', color ='brown', ci= None , estimator= sum)\n",
        "ax.set_title('Rented bikes Vs Holiday ' , fontsize=18)\n",
        "ax.set_xlabel('Holiday',fontsize=15);\n",
        "ax.set_ylabel('Rented Bikes',fontsize=15)"
      ],
      "metadata": {
        "id": "dVNtvBqK3Q7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Here we can assume that Bikes were rented more when there is no holiday and very less as on Holidays.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "adja9lmT5g8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **#Analyze numerical Variables :-** \n"
      ],
      "metadata": {
        "id": "_MQxpXwp5noP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing all the numeric features in a variable list\n",
        "\n",
        "numeric_features =['Rented Bike Count', 'Temperature(°C)', 'Humidity(%)',\n",
        "       'Wind speed (m/s)', 'Visibility (10m)', 'Dew point temperature(°C)',\n",
        "       'Solar Radiation (MJ/m2)', 'Rainfall(mm)', 'Snowfall (cm)']"
      ],
      "metadata": {
        "id": "W5ka_ljf5tTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing displots to analyze the distribution of all numerical features\n",
        "for col in numeric_features:\n",
        "  plt.figure(figsize=(10,6))\n",
        "  sns.distplot(x=df[col] , color ='green')\n",
        "  plt.xlabel(col)\n",
        "  plt.axvline(df[col].mean(),color='magenta', linestyle='dashed',linewidth=2)\n",
        "  plt.axvline(df[col].median(),color='cyan', linestyle='dashed',linewidth=2)\n",
        "  plt.show()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ulS5Rq9457AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.In density plot for*** Rented Bike Count*** we can see the median and mean lies in range of 500 to 1000 mean is slightly greater than median which means its ***positively skewed***.\n",
        "\n",
        "2.In density plot for ***Temperature*** we can see that median is greater than mean we can say to some extend that this is ***negatively skewed***.\n",
        "\n",
        "3.In density plot for ***Humidity*** we can see that mean is greater than median we can say to some extend that this is ***positively skewed***.\n",
        "\n",
        "4.In density plot for ***WindSpeed*** we can see that mean is greater than median we can say to some extend that this is ***positively skewed***.\n",
        "\n",
        "5.In density plot for ***Visibility*** we can see that median is greater than mean we can say to some extend that this is ***negatively skewed***.\n",
        "\n",
        "6.In density plot for ***Dew Point Temperature*** we can see that median is greater than mean we can say to some extend that this is ***negatively skewed***.\n",
        "\n",
        "7.In density plot for ***Solar Radiation*** we can see that mean is greater than median we can say that this is*** positively skewed***."
      ],
      "metadata": {
        "id": "PfrMwXcY6vhg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **#Feature Engineering :-**"
      ],
      "metadata": {
        "id": "bQHsjluM7cTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression plot:-"
      ],
      "metadata": {
        "id": "4rIV6cv47tef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the regression plot for all the numerical features:\n",
        "\n",
        "for col in numeric_features[1:]:\n",
        "  feature = df[col]\n",
        "  label = df['Rented Bike Count']\n",
        "  fig,ax=plt.subplots(figsize=(10,6))\n",
        "  sns.regplot(x=df[col],y=df['Rented Bike Count'],scatter_kws={\"color\": 'pink'}, line_kws={\"color\": \"black\"})\n",
        "  correlation = feature.corr(label)\n",
        "  ax.set_title('Rented Bike Count vs ' + col + '- correlation: ' + str(correlation))"
      ],
      "metadata": {
        "id": "H4GO67WH7xTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above regression plots we can conclude that the columns.\n",
        "\n",
        "*   ***'Rainfall', 'Snowfall', 'Humidity'*** these features are ***negatively ***related with the dependent variaable.\n",
        "*  ***'Temperature', 'Wind_speed','Visibility', 'Dew_point_temperature', 'Solar_Radiation'*** are **positively** correlated with the dependent variable.\n",
        "\n"
      ],
      "metadata": {
        "id": "vY1YKRNy8GBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the correlation plot:\n",
        "\n",
        "corr = df.corr()\n",
        "corr.style.background_gradient(cmap='coolwarm')"
      ],
      "metadata": {
        "id": "jGWHCgFB8WYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temperature and Dew point temperature has highest correlation. Since for Linear Regression model, it is assumed that there is no multi-collinearity between Independent variables, we have remove multi-collinearity from this dataset."
      ],
      "metadata": {
        "id": "qxzuTTtl8fdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **#Checking VIF:-**"
      ],
      "metadata": {
        "id": "rMOARTGP8iBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definig function for VIF:\n",
        "\n",
        "def calc_vif(X):\n",
        " \n",
        "   # Calculating VIF:\n",
        "   \n",
        "   vif = pd.DataFrame()\n",
        "   vif[\"variables\"] = X.columns\n",
        "   vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        " \n",
        "   return(vif)"
      ],
      "metadata": {
        "id": "Vz4nrFw78Y0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(df[[i for i in df.describe().columns if i not in ['Rented Bike Count','Day', 'Month', 'Year']]])"
      ],
      "metadata": {
        "id": "1ITdNAEN8mxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since **Temperature has highest VIF** followed by Dew Point Temperature, we will check for VIF of features without Temperature."
      ],
      "metadata": {
        "id": "qbjYDwU58vI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(df[[i for i in df.describe().columns if i not in ['Rented Bike Count','Day', 'Month', 'Year','Temperature(°C)']]])"
      ],
      "metadata": {
        "id": "WWks5yrN8toB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After **dropping temperature**, VIF is in acceptable range, therefore we will drop temperature from our dataset."
      ],
      "metadata": {
        "id": "pVeTn_Zd88cG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(['Temperature(°C)'],axis=1)"
      ],
      "metadata": {
        "id": "G3nD3MRU87Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking correlation plot after dropping Temperature:\n",
        "corr = df.corr()\n",
        "corr.style.background_gradient(cmap='coolwarm')\n"
      ],
      "metadata": {
        "id": "4ZPZaJtz9CTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordinal encoding:\n",
        "\n",
        "df['Functioning Day']=df['Functioning Day'].map({'Yes':1,'No':0})\n",
        "df['Holiday']=df['Holiday'].map({'No Holiday':0,'Holiday':1})"
      ],
      "metadata": {
        "id": "abNk_0aW9EAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "o9kJt74X9FpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One Hot Encoding:\n",
        "\n",
        "df_seasons=pd.get_dummies( df['Seasons'] )\n",
        "df_month=pd.get_dummies( df['Month'] , prefix = 'Month')\n",
        "df_hour=pd.get_dummies( df['Hour'] ,prefix = 'Hour' )"
      ],
      "metadata": {
        "id": "_Hs1pn9y9NQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join one hot encoded columns:\n",
        "\n",
        "df=df.join([df_seasons,df_month,df_hour])"
      ],
      "metadata": {
        "id": "mSauvtmK9UhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(columns = ['Hour', 'Seasons' ,'Month'])"
      ],
      "metadata": {
        "id": "lFhmUDL99X7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "306JrNiI9Yjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **#Checking Distribution Rented Bike Count column data:-**"
      ],
      "metadata": {
        "id": "v6tpU28v9mzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution plot of Rented Bike Count:\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.xlabel('Rented_Bike_Count')\n",
        "plt.ylabel('Density')\n",
        "ax=sns.distplot(df['Rented Bike Count'],hist=True ,color=\"green\")\n",
        "ax.axvline(df['Rented Bike Count'].mean(), color='blue', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(df['Rented Bike Count'].median(), color='red', linestyle='dashed', linewidth=2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B0svHXLg9azV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   In density plot for ***Rented Bike Count*** we can see the median and mean lies in range of 500 to 1000 mean is slightly **greater than median** which means its ***positively skewed***.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PrMaYzvK97Iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying square root to Rented Bike Count to reduce skewness:\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.xlabel('Rented Bike Count')\n",
        "plt.ylabel('Density')\n",
        "\n",
        "ax=sns.distplot(np.sqrt(df['Rented Bike Count']), color=\"green\")\n",
        "ax.axvline(np.sqrt(df['Rented Bike Count']).mean(), color='blue', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(np.sqrt(df['Rented Bike Count']).median(), color='red', linestyle='dashed', linewidth=2)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v76j7vdV92HZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying square root to Rented Bike Count column:\n",
        "\n",
        "df['Rented Bike Count']=np.sqrt(df['Rented Bike Count'])"
      ],
      "metadata": {
        "id": "p9g6QW8y-lF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining function for plotting y test  and y train values:\n",
        "\n",
        "def get_linear_graph(pred_value , y_test ):\n",
        "  plt.figure(figsize=(15,7))\n",
        "  plt.plot(pred_value[:100])\n",
        "  plt.plot(np.array(y_test[:100]))\n",
        "  plt.legend(['Predicted','Actual'])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "N83SjhfS-nJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining function for feature importance:\n",
        "\n",
        "def get_feat_imp(model):\n",
        "  feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "  plt.figure(figsize=(15,8))\n",
        "  plt.title('Feature Importance')\n",
        "  feat_importances.nlargest(10).plot(kind='barh', color= 'red')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "q5V8xRtA-oKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #Data preparation:-"
      ],
      "metadata": {
        "id": "i3YPJYsw-5iR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating copy of data:\n",
        "# Creating copy of data:\n",
        "\n",
        "data= df.copy()"
      ],
      "metadata": {
        "id": "TIw7JpsO-9cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the data of dependent and independent variables:\n",
        "\n",
        "y = data['Rented Bike Count']\n",
        "X = data.drop(columns=['Rented Bike Count'], axis=1)"
      ],
      "metadata": {
        "id": "hJrPfL_D_ABv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into the Training set and Test set:\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=12)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "IKAv1Lk5_CTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming data:\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "ELZYnz_o_D_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **#Linear Regression:-**"
      ],
      "metadata": {
        "id": "RePlD5MH_IHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting onto Linear regression Model:\n",
        "\n",
        "reg= LinearRegression().fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "JxqGSXQL_MLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the X_train and X-test value:\n",
        "\n",
        "y_pred_train=reg.predict(X_train)\n",
        "y_pred_test=reg.predict(X_test)"
      ],
      "metadata": {
        "id": "RHjpSfJr_vQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evluation Matrix for Linear Regression.**"
      ],
      "metadata": {
        "id": "Ac001ef9_2Vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for training data:\n",
        "\n",
        "\n",
        "MSEl = mean_squared_error((y_train), (y_pred_train))\n",
        "MAEl= mean_absolute_error(y_train, y_pred_train)\n",
        "r2l = r2_score(y_train, y_pred_train)"
      ],
      "metadata": {
        "id": "Ftf3wgaf_xXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for testing data:\n",
        "\n",
        "\n",
        "MSEtestl = mean_squared_error((y_test), (y_pred_test))\n",
        "MAEtestl= mean_absolute_error(y_test, y_pred_test)\n",
        "r2testl = r2_score(y_test, y_pred_test)"
      ],
      "metadata": {
        "id": "5Cas9Z43ADZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Errors:\n",
        "\n",
        "print('Training Errors\\nMSE:', MSEl , '\\nMAE:' , MAEl , '\\nR2:',round((r2l),3))\n",
        "print('\\n\\nTesting Errors\\nMSE:', MSEtestl , '\\nMAE:' , MAEtestl , '\\nR2:',round((r2testl),3))"
      ],
      "metadata": {
        "id": "FpdcEWFaAFXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_linear_graph(y_pred_test , y_test )"
      ],
      "metadata": {
        "id": "C65aONkZAHfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the train set metrics value in a dataframe for later comparison:\n",
        "\n",
        "dict1={'Model':'Linear regression ',\n",
        "       'MAE':round((MAEl),3),\n",
        "       'MSE':round((MSEl),3),\n",
        "       'R2_score':round((r2l),3),\n",
        "       }\n",
        "training_df=pd.DataFrame(dict1,index=[1])"
      ],
      "metadata": {
        "id": "PLjIvyTPAKJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison:\n",
        "dict2={'Model':'Linear regression ',\n",
        "       'MAE':round((MAEtestl),3),\n",
        "       'MSE':round((MSEtestl),3),\n",
        "       'R2_score':round((r2testl),3)\n",
        "       }\n",
        "test_df=pd.DataFrame(dict2,index=[1])"
      ],
      "metadata": {
        "id": "eTm7ccMNAX63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **#Polynomial Regression:-**"
      ],
      "metadata": {
        "id": "sd3ezfr7Abi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting training data onto Polynomial regression Model :\n",
        "\n",
        "poly_reg = PolynomialFeatures(degree = 2)"
      ],
      "metadata": {
        "id": "Jt9oIjB2AaBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_poly = poly_reg.fit_transform(X_train)\n",
        "X_poly_test = poly_reg.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "1m76qg1xAzRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting training data onto Polynomial regression Model:\n",
        "\n",
        "poly = LinearRegression().fit(X_poly, y_train)"
      ],
      "metadata": {
        "id": "p7kfW9z6Az1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the y_train and y-test value:\n",
        "\n",
        "y_pred_poly_train = poly.predict(X_poly)\n",
        "y_pred_poly_test= poly.predict(X_poly_test)"
      ],
      "metadata": {
        "id": "1KXECgQiA3bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Matrix for Polynomial Regression:-"
      ],
      "metadata": {
        "id": "mMBt0ArVA60w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for training data:\n",
        "\n",
        "MSEp = mean_squared_error((y_train), (y_pred_poly_train))\n",
        "MAEp= mean_absolute_error(y_train, y_pred_poly_train)\n",
        "r2p = r2_score(y_train, y_pred_poly_train)"
      ],
      "metadata": {
        "id": "lQ37dx4RA5MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for testing data:\n",
        "\n",
        "MSEtestp = mean_squared_error((y_test), (y_pred_poly_test))\n",
        "MAEtestp= mean_absolute_error(y_test, y_pred_poly_test)\n",
        "r2testp = r2_score(y_test, y_pred_poly_test)"
      ],
      "metadata": {
        "id": "K7hK2_ROA_KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Errors:\n",
        "\n",
        "print('Training Errors\\nMSE:', MSEp , '\\nMAE:' , MAEp , '\\nR2:',round((r2p),2))\n",
        "print('\\n\\nTesting Errors\\nMSE:', MSEtestp , '\\nMAE:' , MAEtestp , '\\nR2:',round((r2testp),2))"
      ],
      "metadata": {
        "id": "sAEzXIVLBBP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_linear_graph(y_pred_poly_test , y_test )"
      ],
      "metadata": {
        "id": "3wC8nAyFBDBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the train set metrics value in a dataframe for later comparison:\n",
        "\n",
        "dict1={'Model':'Polynomial regression ',\n",
        "       'MAE':round((MAEp),3),\n",
        "       'MSE':round((MSEp),3),\n",
        "       'R2_score':round((r2p),3)\n",
        "       }\n",
        "training_df=training_df.append(dict1,ignore_index=True)"
      ],
      "metadata": {
        "id": "mCOt8lFaBEuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison:\n",
        "\n",
        "dict2={'Model':'Polynomial regression ',\n",
        "       'MAE':round((MAEtestp),3),\n",
        "       'MSE':round((MSEtestp),3),\n",
        "       'R2_score':round((r2testp),3)\n",
        "       }\n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "OgLerfmwBG2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **#Decision Tree Regressor:-**"
      ],
      "metadata": {
        "id": "dzAQCG6qBPi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating object wth Decision tree regressor with critera of mean squared error, maximum depth being 10, maximum leaf noodes being 120:\n",
        "\n",
        "decision_regressor = DecisionTreeRegressor(criterion='squared_error', max_depth=10, max_leaf_nodes=120)\n",
        "decision_regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "XEN6I49tBVSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the y_train and y-test value:\n",
        "\n",
        "y_pred_train_d = decision_regressor.predict(X_train)\n",
        "y_pred_test_d = decision_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "9GEkBMVDBYem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **#Evaluation Matrix for Decision Tree Regressor:-**"
      ],
      "metadata": {
        "id": "Eq8L_nqnBb6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for training data:\n",
        "\n",
        "\n",
        "MSEdt = mean_squared_error((y_train), (y_pred_train_d))\n",
        "MAEdt = mean_absolute_error(y_train, y_pred_train_d)\n",
        "r2dt = r2_score(y_train, y_pred_train_d)"
      ],
      "metadata": {
        "id": "ozcjb16TBact"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for testing data:\n",
        "\n",
        "\n",
        "MSEtestdt = mean_squared_error((y_test), (y_pred_test_d))\n",
        "MAEtestdt = mean_absolute_error(y_test, y_pred_test_d)\n",
        "r2testdt = r2_score(y_test, y_pred_test_d)"
      ],
      "metadata": {
        "id": "nsSCWVRlBhBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Errors:\n",
        "\n",
        "print('Training Errors\\nMSE:', MSEdt , '\\nMAE:' , MAEdt , '\\nR2:',round((r2dt),3))\n",
        "print('\\n\\nTesting Errors\\nMSE:', MSEtestdt , '\\nMAE:' , MAEtestdt , '\\nR2:',round((r2testdt),3))"
      ],
      "metadata": {
        "id": "d8amtm4aBjvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_linear_graph(y_pred_test_d , y_test )"
      ],
      "metadata": {
        "id": "ifvxmUfSBm32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the train set metrics value in a dataframe for later comparison:\n",
        "\n",
        "dict1={'Model':'Decision Tree Regression ',\n",
        "       'MAE':round((MAEdt),3),\n",
        "       'MSE':round((MSEdt),3),\n",
        "       'R2_score':round((r2dt),3),\n",
        "}\n",
        "training_df=training_df.append(dict1,ignore_index=True)"
      ],
      "metadata": {
        "id": "oPGlOAvQBoev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2 = {'Model':'Decision Tree Regression ',\n",
        "       'MAE':round((MAEtestdt),3),\n",
        "       'MSE':round((MSEtestdt),3),\n",
        "       'R2_score':round((r2testdt),3),\n",
        "}\n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "68ei3tsdBq8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_feat_imp(decision_regressor)"
      ],
      "metadata": {
        "id": "_sEPjZqwBwLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   List itemHere we can see ***Hour_20*** is showing least feature importance while **Winter season** is showing highest feature importance in model prediction.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IgCQF2GuB4Um"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **#Random Forrest Regressor:-**"
      ],
      "metadata": {
        "id": "pMzVK1SBGY3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestRegressor(n_estimators = 180, random_state = 21 ,criterion= 'mse',max_depth=13 ,max_leaf_nodes= 80)\n",
        "rfc.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "XYzcGP0uBx8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on train dataset:\n",
        "\n",
        "y_pred_trainrfc = rfc.predict(X_train)"
      ],
      "metadata": {
        "id": "S_1-luJhGkYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction on test dataset:\n",
        "\n",
        "y_pred_testrfc = rfc.predict(X_test)"
      ],
      "metadata": {
        "id": "5kQGhd_sGoi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **#Evaluation Matrix for Random Forest:-**"
      ],
      "metadata": {
        "id": "Uv4jcCMAG3GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for training data:\n",
        "\n",
        "\n",
        "MSErfc = mean_squared_error(y_train, y_pred_trainrfc)\n",
        "MAErfc = mean_absolute_error(y_train, y_pred_trainrfc)\n",
        "r2rfc = r2_score(y_train, y_pred_trainrfc)"
      ],
      "metadata": {
        "id": "0DQVRGwQG8tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MSE, MAE, R2 for testing data:\n",
        "\n",
        "\n",
        "MSEtestrf = mean_squared_error((y_test), (y_pred_testrfc))\n",
        "MAEtestrf = mean_absolute_error(y_test, y_pred_testrfc)\n",
        "r2testrf = r2_score(y_test, y_pred_testrfc)\n"
      ],
      "metadata": {
        "id": "0p0ykj0gHAKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Errors:\n",
        "\n",
        "print('Training Errors\\nMSE:', MSErfc , '\\nMAE:' , MAErfc , '\\nR2:',round((r2rfc),3))\n",
        "print('\\n\\nTesting Errors\\nMSE:', MSEtestrf , '\\nMAE:' , MAEtestrf , '\\nR2:',round((r2testrf),3))"
      ],
      "metadata": {
        "id": "waM6-WfyHCWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_linear_graph(y_pred_testrfc , y_test )"
      ],
      "metadata": {
        "id": "1CnH7XhSHE-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the train set metrics value in a dataframe for later comparison:\n",
        "\n",
        "dict1={'Model':'Random Forrest ',\n",
        "       'MAE':round((MAErfc),3),\n",
        "       'MSE':round((MSErfc),3),\n",
        "       'R2_score':round((r2rfc),3)}\n",
        "       \n",
        "training_df=training_df.append(dict1,ignore_index=True)"
      ],
      "metadata": {
        "id": "dgrtYPW4HHE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the train set metrics value in a dataframe for later comparison:\n",
        "\n",
        "dict2={'Model':'Random Forrest ',\n",
        "       'MAE':round((MAEtestrf),3),\n",
        "       'MSE':round((MSEtestrf),3),\n",
        "       'R2_score':round((r2testrf),3)}\n",
        "       \n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "yx1hNAM8HJMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_feat_imp(rfc)"
      ],
      "metadata": {
        "id": "0jyM6HufHK83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see ***Month_3*** is showing least feature importance while **Winter season** is showing highest feature importance in model prediction.\n"
      ],
      "metadata": {
        "id": "X0Mp-5pVHPLF"
      }
    }
  ]
}